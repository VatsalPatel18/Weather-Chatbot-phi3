{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9097f8a2-6394-4d53-bd2f-4c6ede9717b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting unsloth@ git+https://github.com/unslothai/unsloth.git (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Cloning https://github.com/unslothai/unsloth.git to /tmp/pip-install-rvx7roum/unsloth_1da7ff77a5234ed88f8b268c0e57d9de\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/unslothai/unsloth.git /tmp/pip-install-rvx7roum/unsloth_1da7ff77a5234ed88f8b268c0e57d9de\n",
      "  Resolved https://github.com/unslothai/unsloth.git to commit 8d9bd0ea8bf662618ba96fe7fe3478c5b81d0dff\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: tyro in /home/vatsal-patel/anaconda3/lib/python3.11/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.8.4)\n",
      "Requirement already satisfied: transformers>=4.38.2 in /home/vatsal-patel/anaconda3/lib/python3.11/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.41.2)\n",
      "Requirement already satisfied: datasets>=2.16.0 in /home/vatsal-patel/anaconda3/lib/python3.11/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.19.1)\n",
      "Requirement already satisfied: sentencepiece in /home/vatsal-patel/anaconda3/lib/python3.11/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.2.0)\n",
      "Requirement already satisfied: tqdm in /home/vatsal-patel/anaconda3/lib/python3.11/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.65.0)\n",
      "Requirement already satisfied: psutil in /home/vatsal-patel/anaconda3/lib/python3.11/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (5.9.0)\n",
      "Requirement already satisfied: wheel>=0.42.0 in /home/vatsal-patel/anaconda3/lib/python3.11/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.43.0)\n",
      "Requirement already satisfied: numpy in /home/vatsal-patel/anaconda3/lib/python3.11/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.26.4)\n",
      "Requirement already satisfied: protobuf<4.0.0 in /home/vatsal-patel/anaconda3/lib/python3.11/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.20.3)\n",
      "Requirement already satisfied: filelock in /home/vatsal-patel/anaconda3/lib/python3.11/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.13.1)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /home/vatsal-patel/anaconda3/lib/python3.11/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (14.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in /home/vatsal-patel/anaconda3/lib/python3.11/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/vatsal-patel/anaconda3/lib/python3.11/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/vatsal-patel/anaconda3/lib/python3.11/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.1.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/vatsal-patel/anaconda3/lib/python3.11/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.32.3)\n",
      "Requirement already satisfied: xxhash in /home/vatsal-patel/anaconda3/lib/python3.11/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /home/vatsal-patel/anaconda3/lib/python3.11/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.3.1,>=2023.1.0 in /home/vatsal-patel/anaconda3/lib/python3.11/site-packages (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in /home/vatsal-patel/anaconda3/lib/python3.11/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.9.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.2 in /home/vatsal-patel/anaconda3/lib/python3.11/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.23.2)\n",
      "Requirement already satisfied: packaging in /home/vatsal-patel/anaconda3/lib/python3.11/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/vatsal-patel/anaconda3/lib/python3.11/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/vatsal-patel/anaconda3/lib/python3.11/site-packages (from transformers>=4.38.2->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/vatsal-patel/anaconda3/lib/python3.11/site-packages (from transformers>=4.38.2->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/vatsal-patel/anaconda3/lib/python3.11/site-packages (from transformers>=4.38.2->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.4.3)\n",
      "Requirement already satisfied: docstring-parser>=0.14.1 in /home/vatsal-patel/anaconda3/lib/python3.11/site-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.16)\n",
      "Requirement already satisfied: typing-extensions>=4.7.0 in /home/vatsal-patel/anaconda3/lib/python3.11/site-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.9.0)\n",
      "Requirement already satisfied: rich>=11.1.0 in /home/vatsal-patel/anaconda3/lib/python3.11/site-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (13.3.5)\n",
      "Requirement already satisfied: shtab>=1.5.6 in /home/vatsal-patel/anaconda3/lib/python3.11/site-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.7.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/vatsal-patel/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/vatsal-patel/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/vatsal-patel/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/vatsal-patel/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/vatsal-patel/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.9.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/vatsal-patel/anaconda3/lib/python3.11/site-packages (from requests>=2.19.0->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/vatsal-patel/anaconda3/lib/python3.11/site-packages (from requests>=2.19.0->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/vatsal-patel/anaconda3/lib/python3.11/site-packages (from requests>=2.19.0->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/vatsal-patel/anaconda3/lib/python3.11/site-packages (from requests>=2.19.0->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.2.2)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /home/vatsal-patel/anaconda3/lib/python3.11/site-packages (from rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/vatsal-patel/anaconda3/lib/python3.11/site-packages (from rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.15.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/vatsal-patel/anaconda3/lib/python3.11/site-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/vatsal-patel/anaconda3/lib/python3.11/site-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/vatsal-patel/anaconda3/lib/python3.11/site-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2023.3)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/vatsal-patel/anaconda3/lib/python3.11/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/vatsal-patel/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.16.0)\n",
      "Requirement already satisfied: xformers in /home/vatsal-patel/anaconda3/lib/python3.11/site-packages (0.0.26.post1)\n",
      "Requirement already satisfied: trl<0.9.0 in /home/vatsal-patel/anaconda3/lib/python3.11/site-packages (0.8.6)\n",
      "Requirement already satisfied: peft in /home/vatsal-patel/anaconda3/lib/python3.11/site-packages (0.11.1)\n",
      "Requirement already satisfied: accelerate in /home/vatsal-patel/anaconda3/lib/python3.11/site-packages (0.30.1)\n",
      "Requirement already satisfied: bitsandbytes in /home/vatsal-patel/anaconda3/lib/python3.11/site-packages (0.43.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
    "!pip install --no-deps xformers \"trl<0.9.0\" peft accelerate bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fae2edfa-163e-439f-a906-775fadb3d2c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /home/vatsal-patel/anaconda3/lib/python3.11/site-packages (1.5.0)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /home/vatsal-patel/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/vatsal-patel/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/vatsal-patel/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/vatsal-patel/anaconda3/lib/python3.11/site-packages (from scikit-learn) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9e343ed0-66a2-4131-b8c2-896c30e16d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /home/vatsal-patel/anaconda3/lib/python3.11/site-packages (1.5.0)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /home/vatsal-patel/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/vatsal-patel/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/vatsal-patel/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/vatsal-patel/anaconda3/lib/python3.11/site-packages (from scikit-learn) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a31650b-4a44-463d-b97d-8abab6357315",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "import os\n",
    "import json\n",
    "from datasets import load_dataset, Dataset\n",
    "from transformers import TrainingArguments\n",
    "from trl import SFTTrainer\n",
    "from unsloth.chat_templates import get_chat_template\n",
    "from transformers import TextStreamer\n",
    "import requests\n",
    "from transformers import TextStreamer\n",
    "from unsloth.chat_templates import get_chat_template\n",
    "import random\n",
    "from datasets import load_metric\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d318eca-630a-4467-b81f-64b1980eaff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "max_seq_length = 512 # Choose any! We auto support RoPE Scaling internally!\n",
    "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0de2c83-6056-4a2f-bab9-111963a2d59f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth: Fast Mistral patching release 2024.5\n",
      "   \\\\   /|    GPU: NVIDIA GeForce RTX 3050 Ti Laptop GPU. Max memory: 3.811 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.3.0. CUDA = 8.6. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = TRUE. Xformers = 0.0.26.post1. FA = False.\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/Phi-3-mini-4k-instruct\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44e32e83-beca-470f-a30b-845ac67b40a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2024.5 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
    "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
    "    random_state = 3407,\n",
    "    use_rslora = False,  # We support rank stabilized LoRA\n",
    "    loftq_config = None, # And LoftQ\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7681fea0-f92a-4b7b-b389-95edf91acb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "dataset_path = 'data/weather_chatbot_dataset.json'\n",
    "with open(dataset_path, 'r') as f:\n",
    "    weather_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd84fe32-7964-4698-8eef-935d10ad0437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_input': 'What is the current weather in Frankfurt today?',\n",
       " 'intent_extraction': {'intent': 'current_weather',\n",
       "  'entities': {'city': 'Frankfurt', 'date': 'today'}},\n",
       " 'api_response': {'location': 'Frankfurt, DE',\n",
       "  'temperature': 12.76,\n",
       "  'description': 'clear sky',\n",
       "  'wind_speed': 7.2,\n",
       "  'humidity': 62},\n",
       " 'assistant_response': 'The weather in Frankfurt is currently clear sky with a temperature of 12.76°C, wind speed of 7.2 meters per second, and humidity of 62%.'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f449e4b6-b5b7-43e0-93a8-c9d625701c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "intent_identification_data = []\n",
    "assistant_response_data = []\n",
    "\n",
    "for entry in weather_data:\n",
    "    # For intent identification\n",
    "    intent_identification_data.append({\n",
    "        \"user_input\": entry[\"user_input\"],\n",
    "        \"intent_extraction\": entry[\"intent_extraction\"]\n",
    "    })\n",
    "    \n",
    "    # For assistant response generation\n",
    "    assistant_response_data.append({\n",
    "        \"user_input\": entry[\"user_input\"],\n",
    "        \"api_response\": entry[\"api_response\"],\n",
    "        \"assistant_response\": entry[\"assistant_response\"]\n",
    "    })\n",
    "\n",
    "# Combine the datasets\n",
    "combined_data = intent_identification_data + assistant_response_data\n",
    "\n",
    "# Shuffle the combined dataset\n",
    "random.shuffle(combined_data)\n",
    "# train_test_split\n",
    "\n",
    "# Convert to Hugging Face Dataset format\n",
    "combined_dataset = Dataset.from_dict({\"conversations\": combined_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fbe1353c-fa76-4fd1-9944-1dadcf660c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_split = combined_dataset.train_test_split(test_size=0.4)  # 80% train, 20% validation\n",
    "train_dataset = dataset_split['train']\n",
    "val_dataset = dataset_split['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5778f8c6-a20c-44f8-a089-959ba8c5fcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5b3b4e65-571d-44b6-85a9-21f468a090f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datasets import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b4bb7b72-b528-4e4e-b319-8e24c6298e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_dict['intent_identification'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6593e2b7-7f15-478e-a548-2609e556852b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_dict['assistant_response'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "574abc30-4cb6-475d-8a0f-b145388ac14c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████████████████████| 796/796 [00:00<00:00, 15362.55 examples/s]\n",
      "Map: 100%|██████████████████████████| 532/532 [00:00<00:00, 24157.39 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from unsloth.chat_templates import get_chat_template\n",
    "from typing import Dict, List\n",
    "\n",
    "tokenizer = get_chat_template(\n",
    "    tokenizer,\n",
    "    chat_template=\"phi-3\",\n",
    "    mapping={\"role\": \"from\", \"content\": \"value\", \"user\": \"human\", \"assistant\": \"gpt\", \"API\": \"api\"},\n",
    ")\n",
    "\n",
    "def format_combined_prompts(batch: Dict[str, List[Dict]], tokenizer):\n",
    "    def format_conversation(example: Dict[str, str]):\n",
    "        conversation = [{\"from\": \"human\", \"value\": example['user_input']}]\n",
    "        if \"intent_extraction\" in example and example['intent_extraction'] is not None:\n",
    "            conversation.append({\"from\": \"gpt\", \"value\": str(example['intent_extraction'])})\n",
    "        if \"api_response\" in example and example['api_response'] is not None:\n",
    "            conversation.append({\"from\": \"api\", \"value\": str(example['api_response'])})\n",
    "            if \"assistant_response\" in example and example['assistant_response'] is not None:\n",
    "                conversation.append({\"from\": \"gpt\", \"value\": example['assistant_response']})\n",
    "        return conversation\n",
    "\n",
    "    texts = [tokenizer.apply_chat_template(format_conversation(example), tokenize=False, add_generation_prompt=True) for example in batch[\"conversations\"]]\n",
    "    return {\"text\": texts}\n",
    "\n",
    "# Apply formatting\n",
    "train_dataset = train_dataset.map(lambda batch: format_combined_prompts(batch, tokenizer), batched=True)\n",
    "val_dataset = val_dataset.map(lambda batch: format_combined_prompts(batch, tokenizer), batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f35072a-c06c-4daf-8e53-681dcfbeab20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conversations': {'api_response': None,\n",
       "  'assistant_response': None,\n",
       "  'intent_extraction': {'entities': {'city': 'Toulouse', 'date': 'today'},\n",
       "   'intent': 'current_weather'},\n",
       "  'user_input': 'What is the current weather in Toulouse today?'},\n",
       " 'text': \"<s><|user|>\\nWhat is the current weather in Toulouse today?<|end|>\\n<|assistant|>\\n{'entities': {'city': 'Toulouse', 'date': 'today'}, 'intent': 'current_weather'}<|end|>\\n<|assistant|>\\n\"}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b05e5613-ae79-4778-bc38-a20510bbb4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # BLEU\n",
    "    bleu = load_metric(\"bleu\")\n",
    "    bleu_result = bleu.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "\n",
    "    # ROUGE\n",
    "    rouge = load_metric(\"rouge\")\n",
    "    rouge_result = rouge.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "\n",
    "    # Perplexity\n",
    "    perplexity = torch.exp(torch.tensor(eval_pred[0].mean()))\n",
    "\n",
    "    return {\n",
    "        \"bleu\": bleu_result['bleu'],\n",
    "        \"rouge\": rouge_result['rougeL'].mid.fmeasure,\n",
    "        \"perplexity\": perplexity.item(),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "54b08b0c-e1c7-4c44-a70c-2f9b7a9e2d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=4,\n",
    "    warmup_steps=5,\n",
    "    max_steps=60,\n",
    "    learning_rate=2e-4,\n",
    "    fp16=not torch.cuda.is_bf16_supported(),\n",
    "    bf16=torch.cuda.is_bf16_supported(),\n",
    "    logging_steps=1,\n",
    "    optim=\"adamw_8bit\",\n",
    "    weight_decay=0.01,\n",
    "    lr_scheduler_type=\"linear\",\n",
    "    seed=3407,\n",
    "    output_dir=\"outputs_combined\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "48dc6600-8028-424b-8793-c973a1c2098b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=2): 100%|██████████████| 832/832 [00:00<00:00, 3409.01 examples/s]\n",
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    }
   ],
   "source": [
    "# Combined training\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=combined_dataset,\n",
    "    eval_dataset=combined_dataset,  # You may want to separate a validation dataset\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=max_seq_length,\n",
    "    dataset_num_proc=2,\n",
    "    packing=False,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3b93a8aa-d40e-46a7-90ae-913de5db42eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 832 | Num Epochs = 1\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n",
      "\\        /    Total batch size = 8 | Total steps = 60\n",
      " \"-____-\"     Number of trainable parameters = 29,884,416\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [60/60 03:06, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.177800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.981800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.052000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.676000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.517800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.068500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.830400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.668800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.389000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.195900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.083100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.919500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.812600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.727600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.671500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.608900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.531500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.471900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.402300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.344700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.366300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.351200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.449100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.349500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.358900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.299400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.226000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.355200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.260600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.326500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.306600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.262900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.263100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.282900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.282100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.275200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.234200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.290700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.217300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.284000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.221900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.176500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.220600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.171400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.210300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.212000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.248600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.251800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.280100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.232300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.301200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.261200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.208100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.265500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.242400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.268600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.256100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.213700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.243100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.254300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer_stats = trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0d78665b-4749-4929-b0f0-b3138efd64ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adapter_model.safetensors: 100%|█████████████| 120M/120M [00:40<00:00, 2.92MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to https://huggingface.co/VatsalPatel18/phi3-mini-WeatherBot\n"
     ]
    }
   ],
   "source": [
    "model.push_to_hub(\"VatsalPatel18/phi3-mini-WeatherBot\", token=os.getenv(\"HUGGINGFACE_HUB_TOKEN\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04cda88-5643-45bd-903a-82c6ce6c035f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import Trainer, TrainingArguments, AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import load_dataset, load_metric\n",
    "from datasets import load_metric\n",
    "\n",
    "\n",
    "# Load your model and tokenizer\n",
    "# model_name = \"your_model_name\"\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Load your dataset\n",
    "# dataset = load_dataset(\"your_dataset_name\")\n",
    "\n",
    "# Define compute_metrics function\n",
    "\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=3,\n",
    "    save_steps=10_000,\n",
    "    eval_steps=1_000,\n",
    "    logging_steps=1_000,\n",
    "    learning_rate=5e-5,\n",
    "    output_dir=\"./results\",\n",
    "    overwrite_output_dir=True,\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"validation\"],\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate the model\n",
    "metrics = trainer.evaluate()\n",
    "print(metrics)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Unsloth)",
   "language": "python",
   "name": "unsloth_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
