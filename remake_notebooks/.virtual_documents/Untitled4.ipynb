import requests
import re
from typing import Optional, Union
from datetime import datetime, timedelta
from llama_cpp import Llama
from llama_cpp_agent import LlamaCppAgent, MessagesFormatterType, LlamaCppFunctionTool
from llama_cpp_agent.providers import LlamaCppPythonProvider
from llama_cpp_agent.chat_history import BasicChatHistory
from llama_cpp_agent.chat_history.messages import Roles
import gradio as gr


# Set up the LLM
model_path = "../models/Phi-3-mini-4k-instruct-gguf/Phi-3-mini-4k-instruct-q4.gguf"
llm_model = Llama(model_path=model_path, n_ctx=4096, n_threads=8)

# Create the weather tool
weather_tool = FunctionTool.from_defaults(
    fn=get_weather,
    name="get_weather",
    description="Get the current weather for a specified city"
)


# Create the agent
agent = ReActAgent.from_tools([weather_tool], llm=llm, verbose=True)

# Example usage
response = agent.chat("What's the weather like in London today?")
print(response)


llm.context_params.n_ctx


llm.metadata.context_window = llm.context_params.n_ctx



