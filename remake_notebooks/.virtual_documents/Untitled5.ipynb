from llama_index.core.tools import FunctionTool
from llama_cpp import Llama
from llama_index.agent.openai import OpenAIAgent
from llama_index.core.settings import Settings

import requests
from typing import Dict, Any, Optional
from pydantic import BaseModel, Field

API_KEY = 'c6dfc4d92a8f972d237ef696ec87b37a'

class WeatherResponse(BaseModel):
    description: str
    temperature: float
    feels_like: float
    humidity: int
    wind_speed: float

def get_weather(
    city: str = Field(description="The name of the city to get weather for"),
    units: str = Field(default="metric", description="Unit system: 'metric' or 'imperial'")
) -> Optional[WeatherResponse]:
    """
    Fetch current weather data for a specified city.
    """
    url = f"http://api.openweathermap.org/data/2.5/weather?q={city}&appid={API_KEY}&units={units}"
    response = requests.get(url)
    
    if response.status_code == 200:
        data = response.json()
        return WeatherResponse(
            description=data['weather'][0]['description'],
            temperature=data['main']['temp'],
            feels_like=data['main']['feels_like'],
            humidity=data['main']['humidity'],
            wind_speed=data['wind']['speed']
        )
    return None

def format_weather_response(weather: WeatherResponse, city: str, units: str) -> str:
    temp_unit = "째C" if units == "metric" else "째F"
    speed_unit = "m/s" if units == "metric" else "mph"
    
    return (
        f"The weather in {city} is currently {weather.description}. "
        f"The temperature is {weather.temperature}{temp_unit}, "
        f"but it feels like {weather.feels_like}{temp_unit}. "
        f"The humidity is {weather.humidity}% and the wind speed is {weather.wind_speed}{speed_unit}."
    )

def weather_tool(city: str, units: str = "metric") -> str:
    """
    Get the current weather for a specified city.
    """
    weather = get_weather(city, units)
    if weather:
        return format_weather_response(weather, city, units)
    return f"Sorry, I couldn't fetch the weather information for {city}."


model_path = "../models/Phi-3-mini-4k-instruct-gguf/Phi-3-mini-4k-instruct-q4.gguf"
llm = Llama(model_path=model_path, context_window=4096, max_new_tokens=512)
Settings.llm = llm

# Create the weather tool
weather_function_tool = FunctionTool.from_defaults(
    fn=weather_tool,
    name="get_weather",
    description="Get the current weather for a specified city"
)


# Create the agent
agent = OpenAIAgent.from_tools([weather_function_tool], llm=llm, verbose=True)

# Example usage
response = agent.chat("What's the weather like in London today?")
print(response)





from llama_cpp import Llama
from langchain.agents import Tool
from langchain.agents import initialize_agent
from langchain_community.llms import LlamaCpp

# 1. Load Your Llama.cpp Model
llm = LlamaCpp(model_path="../models/Phi-3-mini-4k-instruct-gguf/Phi-3-mini-4k-instruct-q4.gguf")  # Replace with your model's path

# 2. Define LangChain Tools (Example: Calculator)
def calculator_tool(input_str):
    """Simple calculator tool."""
    try:
        result = eval(input_str)
        return str(result)
    except Exception:
        return "Invalid calculation"

tools = [
    Tool(
        name="Calculator",
        func=calculator_tool,
        description="Useful for when you need to perform mathematical calculations."
    ),
    # Add more tools as needed
]

# 3. Initialize Agent
agent = initialize_agent(tools, llm, agent="zero-shot-react-description", verbose=True)

# 4. Use the Agent
agent.run("What is the square root of 625?") 



agent.run("What is the square root of 25?") 


agent.run("What is the product of 756 * 565?") 


import requests
from langchain.agents import Tool
from langchain.llms import LlamaCpp 

api_key = "c6dfc4d92a8f972d237ef696ec87b37a" # Replace with your actual OpenWeatherMap API key

def get_weather_info(city):
    """Fetches current weather and basic forecast for a city using OpenWeatherMap API."""
    
    # Current Weather
    url_current = f"http://api.openweathermap.org/data/2.5/weather?q={city}&appid={api_key}&units=metric"
    response_current = requests.get(url_current)
    if response_current.status_code != 200:
        return "Error: Could not fetch weather data."
    data_current = response_current.json()

    # Extract Relevant Information
    description = data_current['weather'][0]['description']
    temperature = data_current['main']['temp']
    feels_like = data_current['main']['feels_like']
    humidity = data_current['main']['humidity']
    wind_speed = data_current['wind']['speed']
    
    # Formulate Response
    response = f"The weather in {city} is currently {description} with a temperature of {temperature}째C (feels like {feels_like}째C). Humidity is {humidity}% and wind speed is {wind_speed} m/s."
    return response

weather_tool = Tool(
    name="WeatherLookup",
    func=get_weather_info,
    description="Useful to get the current weather information and basic forecast for a city."
)



# Load Llama.cpp Model (Same as before)
llm = LlamaCpp(model_path="../models/Phi-3-mini-4k-instruct-gguf/Phi-3-mini-4k-instruct-q4.gguf")  

# Tools (Include our new Weather Tool)
tools = [weather_tool]

# Initialize Agent
agent = initialize_agent(tools, llm, agent="zero-shot-react-description", verbose=True) 

# Get Weather Information
agent.run("What's the weather like in New York?")



agent.run("how is the weather in Kalyani ?")


agent.run("how is the weather in Kolkata ?")


agent.run("Can you tell me tommorow mornings weather in Kalyani ?")



