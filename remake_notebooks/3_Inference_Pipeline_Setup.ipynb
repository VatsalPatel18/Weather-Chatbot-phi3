{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a7eab19-bd2a-4116-ac4f-2270e6df897c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51830e72-9d73-439b-92f7-c2ef36ca9241",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = 'c6dfc4d92a8f972d237ef696ec87b37a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb22d114-a4b8-4823-80c1-009f79c984bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather(city):\n",
    "    url = f\"http://api.openweathermap.org/data/2.5/weather?q={city}&appid={api_key}&units=metric\"\n",
    "    response = requests.get(url)\n",
    "    return response.json() if response.status_code == 200 else None\n",
    "\n",
    "def get_forecast(city):\n",
    "    url = f\"http://api.openweathermap.org/data/2.5/forecast?q={city}&appid={api_key}&units=metric\"\n",
    "    response = requests.get(url)\n",
    "    return response.json() if response.status_code == 200 else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2af14baa-7bc5-4b23-bec7-993c83817b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_intent_data(intent_response):\n",
    "    json_pattern = re.compile(r'\\{.*\\}')\n",
    "    json_match = json_pattern.search(intent_response)\n",
    "    if json_match:\n",
    "        intent_data_str = json_match.group()\n",
    "        intent_data_str = intent_data_str.replace(\"'\", \"\\\"\")\n",
    "        try:\n",
    "            return json.loads(intent_data_str)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding JSON: {e}\")\n",
    "    return {}\n",
    "\n",
    "def fetch_weather_data(intent, city):\n",
    "    if intent == \"current_weather\":\n",
    "        return get_weather(city)\n",
    "    elif intent == \"forecast\" or intent == 'forecast_weather':\n",
    "        return get_forecast(city)\n",
    "    return None\n",
    "\n",
    "def parse_forecast(api_response, city):\n",
    "    if not api_response:\n",
    "        return \"Sorry, I couldn't fetch the weather information.\"\n",
    "\n",
    "    forecast_list = api_response['list']\n",
    "    tomorrow_date = (datetime.utcnow() + timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "    filtered_forecasts = [forecast for forecast in forecast_list if tomorrow_date in forecast['dt_txt']]\n",
    "    \n",
    "    if filtered_forecasts:\n",
    "        selected_forecast = filtered_forecasts[0]\n",
    "        forecast_temp = selected_forecast['main']['temp']\n",
    "        forecast_weather = selected_forecast['weather'][0]['description']\n",
    "        wind_speed = selected_forecast['wind']['speed']\n",
    "        humidity = selected_forecast['main']['humidity']\n",
    "\n",
    "        return (\n",
    "            f\"The forecast for {city} on {tomorrow_date} is {forecast_weather} with a temperature of {forecast_temp}Â°C, \"\n",
    "            f\"wind speed of {wind_speed} meters per second, and humidity of {humidity}%.\"\n",
    "        )\n",
    "    return f\"Sorry, I couldn't fetch the weather information for {city} for tomorrow.\"\n",
    "\n",
    "def generate_assistant_response(user_input, api_response, model, tokenizer):\n",
    "    messages = [\n",
    "        {\"from\": \"human\", \"value\": user_input},\n",
    "        {\"from\": \"api\", \"value\": api_response}\n",
    "    ]\n",
    "    inputs = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=True,\n",
    "        add_generation_prompt=True,\n",
    "        return_tensors=\"pt\",\n",
    "    ).to(\"cuda\")\n",
    "\n",
    "    outputs = model.generate(input_ids=inputs, max_new_tokens=64, use_cache=True)\n",
    "    return tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86b71cdd-9b4f-4782-b26d-bc744ec5ef08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_pipeline(user_input, model, tokenizer):\n",
    "    # Step 1: Intent Identification\n",
    "    messages = [{\"from\": \"human\", \"value\": user_input}]\n",
    "    inputs = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=True,\n",
    "        add_generation_prompt=True,\n",
    "        return_tensors=\"pt\",\n",
    "    ).to(\"cuda\")\n",
    "\n",
    "    intent_output = model.generate(input_ids=inputs, max_new_tokens=64, use_cache=True)\n",
    "    intent_response = tokenizer.batch_decode(intent_output, skip_special_tokens=True)[0]\n",
    "\n",
    "    # Extract intent data\n",
    "    intent_data = extract_intent_data(intent_response)\n",
    "    intent = intent_data.get(\"intent\")\n",
    "    city = intent_data.get(\"entities\", {}).get(\"city\")\n",
    "    date = intent_data.get(\"entities\", {}).get(\"date\")\n",
    "\n",
    "    # Step 2: Fetch weather data from API\n",
    "    api_response = fetch_weather_data(intent, city)\n",
    "    parsed_response = parse_forecast(api_response, city)\n",
    "\n",
    "    # Step 3: Generate the final assistant response using LLM\n",
    "    final_response = generate_assistant_response(user_input, parsed_response, model, tokenizer)\n",
    "    return final_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a32a52-6769-42c2-bcce-dcb8ea66f5a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Unsloth)",
   "language": "python",
   "name": "unsloth_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
