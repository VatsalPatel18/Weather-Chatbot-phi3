{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a7eab19-bd2a-4116-ac4f-2270e6df897c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51830e72-9d73-439b-92f7-c2ef36ca9241",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = 'c6dfc4d92a8f972d237ef696ec87b37a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb22d114-a4b8-4823-80c1-009f79c984bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather(city):\n",
    "    url = f\"http://api.openweathermap.org/data/2.5/weather?q={city}&appid={api_key}&units=metric\"\n",
    "    response = requests.get(url)\n",
    "    return response.json() if response.status_code == 200 else None\n",
    "\n",
    "def get_forecast(city):\n",
    "    url = f\"http://api.openweathermap.org/data/2.5/forecast?q={city}&appid={api_key}&units=metric\"\n",
    "    response = requests.get(url)\n",
    "    return response.json() if response.status_code == 200 else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2af14baa-7bc5-4b23-bec7-993c83817b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_intent_data(intent_response):\n",
    "    json_pattern = re.compile(r'\\{.*\\}')\n",
    "    json_match = json_pattern.search(intent_response)\n",
    "    if json_match:\n",
    "        intent_data_str = json_match.group()\n",
    "        intent_data_str = intent_data_str.replace(\"'\", \"\\\"\")\n",
    "        try:\n",
    "            return json.loads(intent_data_str)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding JSON: {e}\")\n",
    "    return {}\n",
    "\n",
    "def fetch_weather_data(intent, city):\n",
    "    if intent == \"current_weather\":\n",
    "        return get_weather(city)\n",
    "    elif intent == \"forecast\" or intent == 'forecast_weather':\n",
    "        return get_forecast(city)\n",
    "    return None\n",
    "\n",
    "def parse_forecast(api_response, city):\n",
    "    if not api_response:\n",
    "        return \"Sorry, I couldn't fetch the weather information.\"\n",
    "\n",
    "    forecast_list = api_response.get('list', [])\n",
    "    if not forecast_list:\n",
    "        return f\"Sorry, I couldn't fetch the weather information for {city}.\"\n",
    "\n",
    "    tomorrow_date = (datetime.utcnow() + timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "    filtered_forecasts = [forecast for forecast in forecast_list if tomorrow_date in forecast['dt_txt']]\n",
    "    \n",
    "    if filtered_forecasts:\n",
    "        selected_forecast = filtered_forecasts[0]\n",
    "        forecast_temp = selected_forecast['main']['temp']\n",
    "        forecast_weather = selected_forecast['weather'][0]['description']\n",
    "        wind_speed = selected_forecast['wind']['speed']\n",
    "        humidity = selected_forecast['main']['humidity']\n",
    "\n",
    "        return (\n",
    "            f\"The forecast for {city} on {tomorrow_date} is {forecast_weather} with a temperature of {forecast_temp}°C, \"\n",
    "            f\"wind speed of {wind_speed} meters per second, and humidity of {humidity}%.\"\n",
    "        )\n",
    "    return f\"Sorry, I couldn't fetch the weather information for {city} for tomorrow.\"\n",
    "\n",
    "def parse_current_weather(api_response, city):\n",
    "    if not api_response:\n",
    "        return \"Sorry, I couldn't fetch the weather information.\"\n",
    "\n",
    "    main = api_response.get('main', {})\n",
    "    weather = api_response.get('weather', [{}])[0]\n",
    "    wind = api_response.get('wind', {})\n",
    "    \n",
    "    temp = main.get('temp')\n",
    "    description = weather.get('description')\n",
    "    wind_speed = wind.get('speed')\n",
    "    humidity = main.get('humidity')\n",
    "\n",
    "    return (\n",
    "        f\"The current weather in {city} is {description} with a temperature of {temp}°C, \"\n",
    "        f\"wind speed of {wind_speed} meters per second, and humidity of {humidity}%.\"\n",
    "    )\n",
    "\n",
    "# def generate_assistant_response(user_input, api_response, model, tokenizer):\n",
    "#     messages = [\n",
    "#         {\"from\": \"human\", \"value\": user_input},\n",
    "#         {\"from\": \"api\", \"value\": api_response}\n",
    "#     ]\n",
    "#     inputs = tokenizer.apply_chat_template(\n",
    "#         messages,\n",
    "#         tokenize=True,\n",
    "#         add_generation_prompt=True,\n",
    "#         return_tensors=\"pt\",\n",
    "#     ).to(\"cuda\")\n",
    "\n",
    "#     outputs = model.generate(input_ids=inputs, max_new_tokens=64, use_cache=True)\n",
    "#     return tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d079bbbc-d1f6-4735-913c-bea8c3f6e0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_assistant_response(user_input, api_response, model, tokenizer):\n",
    "    messages = [\n",
    "        {\"from\": \"human\", \"value\": user_input},\n",
    "        {\"from\": \"api\", \"value\": api_response}\n",
    "    ]\n",
    "    inputs = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=True,\n",
    "        add_generation_prompt=True,\n",
    "        return_tensors=\"pt\",\n",
    "    ).to(\"cuda\")\n",
    "\n",
    "    outputs = model.generate(input_ids=inputs, max_new_tokens=64, use_cache=True)\n",
    "    response_text = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
    "    \n",
    "    # Extract only the relevant part\n",
    "    return extract_relevant_part(response_text)\n",
    "\n",
    "def extract_relevant_part(response_text):\n",
    "    pattern = re.compile(r'The (current )?weather in .+ is .+ with a temperature of .+°C, wind speed of .+ meters per second, and humidity of .+%.')\n",
    "    match = pattern.search(response_text)\n",
    "    if match:\n",
    "        return match.group()\n",
    "    return response_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86b71cdd-9b4f-4782-b26d-bc744ec5ef08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def inference_pipeline(user_input, model, tokenizer):\n",
    "#     # Step 1: Intent Identification\n",
    "#     messages = [{\"from\": \"human\", \"value\": user_input}]\n",
    "#     inputs = tokenizer.apply_chat_template(\n",
    "#         messages,\n",
    "#         tokenize=True,\n",
    "#         add_generation_prompt=True,\n",
    "#         return_tensors=\"pt\",\n",
    "#     ).to(\"cuda\")\n",
    "\n",
    "#     intent_output = model.generate(input_ids=inputs, max_new_tokens=64, use_cache=True)\n",
    "#     intent_response = tokenizer.batch_decode(intent_output, skip_special_tokens=True)[0]\n",
    "\n",
    "#     # Extract intent data\n",
    "#     intent_data = extract_intent_data(intent_response)\n",
    "#     intent = intent_data.get(\"intent\")\n",
    "#     city = intent_data.get(\"entities\", {}).get(\"city\")\n",
    "#     date = intent_data.get(\"entities\", {}).get(\"date\")\n",
    "\n",
    "#     # Step 2: Fetch weather data from API\n",
    "#     api_response = fetch_weather_data(intent, city)\n",
    "#     if intent == \"current_weather\":\n",
    "#         parsed_response = parse_current_weather(api_response, city)\n",
    "#     else:\n",
    "#         parsed_response = parse_forecast(api_response, city)\n",
    "\n",
    "#     # Step 3: Generate the final assistant response using LLM\n",
    "#     final_response = generate_assistant_response(user_input, parsed_response, model, tokenizer)\n",
    "#     return final_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92fed55a-f22c-4f53-8b00-1d56e53009f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_pipeline(user_input, model, tokenizer):\n",
    "    # Step 1: Intent Identification\n",
    "    messages = [{\"from\": \"human\", \"value\": user_input}]\n",
    "    inputs = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=True,\n",
    "        add_generation_prompt=True,\n",
    "        return_tensors=\"pt\",\n",
    "    ).to(\"cuda\")\n",
    "\n",
    "    intent_output = model.generate(input_ids=inputs, max_new_tokens=64, use_cache=True)\n",
    "    intent_response = tokenizer.batch_decode(intent_output, skip_special_tokens=True)[0]\n",
    "\n",
    "    # Extract intent data\n",
    "    intent_data = extract_intent_data(intent_response)\n",
    "    intent = intent_data.get(\"intent\")\n",
    "    city = intent_data.get(\"entities\", {}).get(\"city\")\n",
    "    date = intent_data.get(\"entities\", {}).get(\"date\")\n",
    "\n",
    "    # Step 2: Fetch weather data from API\n",
    "    api_response = fetch_weather_data(intent, city)\n",
    "    if intent == \"current_weather\":\n",
    "        parsed_response = parse_current_weather(api_response, city)\n",
    "    else:\n",
    "        parsed_response = parse_forecast(api_response, city)\n",
    "\n",
    "    # Step 3: Generate the final assistant response using LLM\n",
    "    final_response = generate_assistant_response(user_input, parsed_response, model, tokenizer)\n",
    "    return final_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4a32a52-6769-42c2-bcce-dcb8ea66f5a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vatsal-patel/anaconda3/envs/unsloth_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "==((====))==  Unsloth: Fast Mistral patching release 2024.5\n",
      "   \\\\   /|    GPU: NVIDIA GeForce RTX 3050 Ti Laptop GPU. Max memory: 3.811 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.3.0. CUDA = 8.6. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = TRUE. Xformers = 0.0.26.post1. FA = False.\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Unsloth 2024.5 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "\n",
    "# model ,tokenizer = FastLanguageModel.from_pretrained(\"../models/trained\")\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"../models/trained\",\n",
    "    max_seq_length = 512,\n",
    "    dtype = None,\n",
    "    load_in_4bit = True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e55b4b2c-6f94-4c6e-b303-4c168deb3417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Assistant Response: What is the weather in Kalyani on 26 June 2024? <|api|>\n",
      "The forecast for Kalyani on 2024-06-13 is broken clouds with a temperature of 28.71°C, wind speed of 6.44 meters per second, and humidity of 74%. The forecast for Kalyani on 2024-06-13 is broken clouds with a temperature of 28.71°C, wind speed of 6.44 meters per second, and humidity of 74%.\n"
     ]
    }
   ],
   "source": [
    "user_input = \"What is the weather in Kalyani on 26 June 2024?\"\n",
    "final_response = inference_pipeline(user_input, model, tokenizer)\n",
    "print(\"Final Assistant Response:\", final_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00a2044e-9488-4700-b8aa-568555cce3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Assistant Response: The current weather in Kalyani is broken clouds with a temperature of 35.95°C, wind speed of 9.41 meters per second, and humidity of 35%. The weather in Kalyani is currently broken clouds with a temperature of 35.95°C, wind speed of 9.41 meters per second, and humidity of 35%.\n"
     ]
    }
   ],
   "source": [
    "user_input = \"What is the weather in Kalyani on Today?\"\n",
    "final_response = inference_pipeline(user_input, model, tokenizer)\n",
    "print(\"Final Assistant Response:\", final_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87220134-acde-4534-87eb-aa5df1b93e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Assistant Response: The current weather in Kalyani is broken clouds with a temperature of 35.95°C, wind speed of 9.41 meters per second, and humidity of 35%. The weather in Kalyani is currently broken clouds with a temperature of 35.95°C, wind speed of 9.41 meters per second, and humidity of 35%.\n"
     ]
    }
   ],
   "source": [
    "user_input = \"What is the weather in Kalyani evening?\"\n",
    "final_response = inference_pipeline(user_input, model, tokenizer)\n",
    "print(\"Final Assistant Response:\", final_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b42f687d-00cb-4fa7-917e-3ecfdac81372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e59570a-f60f-4ac0-93cf-3a7ad2c39836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Assistant Response: The weather in Kalyani on 2024-06-13 is broken clouds with a temperature of 28.71°C, wind speed of 6.44 meters per second, and humidity of 74%.\n"
     ]
    }
   ],
   "source": [
    "user_input = \"What is the weather in Kalyani Tommorow\"\n",
    "final_response = inference_pipeline(user_input, model, tokenizer)\n",
    "print(\"Final Assistant Response:\", final_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2daa16c0-b899-4894-9be4-90b5cea93287",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Unsloth)",
   "language": "python",
   "name": "unsloth_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
