{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cae433d-5fe3-4575-8398-9c97707143eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from langchain.agents import Tool\n",
    "from langchain.llms import LlamaCpp \n",
    "from langchain.agents import initialize_agent\n",
    "from collections import defaultdict\n",
    "import json\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dbf56c8-4258-4851-8f87-7d51789d4762",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = 'c6dfc4d92a8f972d237ef696ec87b37a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "178bfc95-9ae5-4c02-a5ec-04e664fc130d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather_info(city):\n",
    "    \"\"\"Fetches current weather information for a city using OpenWeatherMap API.\"\"\"\n",
    "    \n",
    "    url_current = f\"http://api.openweathermap.org/data/2.5/weather?q={city}&appid={api_key}&units=metric\"\n",
    "    response_current = requests.get(url_current)\n",
    "    if response_current.status_code != 200:\n",
    "        return \"Error: Could not fetch weather data.\"\n",
    "    data_current = response_current.json()\n",
    "\n",
    "    response = {\n",
    "        'coordinates': data_current['coord'],\n",
    "        'weather': data_current['weather'][0],\n",
    "        'temperature': {\n",
    "            'current': data_current['main']['temp'],\n",
    "            'feels_like': data_current['main']['feels_like'],\n",
    "            'min': data_current['main']['temp_min'],\n",
    "            'max': data_current['main']['temp_max']\n",
    "        },\n",
    "        'pressure': {\n",
    "            'sea_level': data_current['main'].get('sea_level', data_current['main']['pressure']),\n",
    "            'ground_level': data_current['main'].get('grnd_level', data_current['main']['pressure'])\n",
    "        },\n",
    "        'humidity': data_current['main']['humidity'],\n",
    "        'visibility': data_current['visibility'],\n",
    "        'wind': data_current['wind'],\n",
    "        'clouds': data_current['clouds'],\n",
    "        'rain': data_current.get('rain', {}),\n",
    "        'dt': data_current['dt'],\n",
    "        'sys': data_current['sys'],\n",
    "        'timezone': data_current['timezone'],\n",
    "        'id': data_current['id'],\n",
    "        'name': data_current['name'],\n",
    "        'cod': data_current['cod']\n",
    "    }\n",
    "\n",
    "    return json.dumps(response, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5c35881-d780-4608-b8da-bf58042c21c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def restructure_forecast(forecast_json):\n",
    "    \"\"\"Restructures the forecast JSON data into a nested dictionary by date and time.\"\"\"\n",
    "    structured_data = defaultdict(dict)\n",
    "    today = datetime.today().strftime('%Y-%m-%d')\n",
    "    next_day = (datetime.today() + timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "    \n",
    "    for entry in forecast_json['list']:\n",
    "        date, time = entry['dt_txt'].split()\n",
    "        if date == next_day:\n",
    "            structured_data[date][time] = {\n",
    "                'temperature': entry['main']['temp'],\n",
    "                'feels_like': entry['main']['feels_like'],\n",
    "                'temp_min': entry['main']['temp_min'],\n",
    "                'temp_max': entry['main']['temp_max'],\n",
    "                'pressure': entry['main']['pressure'],\n",
    "                'humidity': entry['main']['humidity'],\n",
    "                'weather': entry['weather'][0]['description'],\n",
    "                'icon': entry['weather'][0]['icon'],\n",
    "                'wind_speed': entry['wind']['speed'],\n",
    "                'wind_deg': entry['wind']['deg'],\n",
    "                'visibility': entry['visibility'],\n",
    "                'pop': entry['pop'],\n",
    "                'rain': entry.get('rain', {}).get('3h', 0),\n",
    "                'clouds': entry['clouds']['all']\n",
    "            }\n",
    "    return structured_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "299ca33b-f880-4464-a15f-f6f195543ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_forecast(city):\n",
    "    \"\"\"Fetches weather forecast for a city using OpenWeatherMap API.\"\"\"\n",
    "    \n",
    "    url_forecast = f\"http://api.openweathermap.org/data/2.5/forecast?q={city}&appid={api_key}&units=metric\"\n",
    "    response_forecast = requests.get(url_forecast)\n",
    "    if response_forecast.status_code != 200:\n",
    "        return \"Error: Could not fetch forecast data.\"\n",
    "    data_forecast = response_forecast.json()\n",
    "    return restructure_forecast(data_forecast)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8b250d1e-084c-46ae-9ddd-78aba0462b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the forecast data\n",
    "# forecast_data = get_forecast('London')\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c0f91d26-9977-426a-847c-2e8694054c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forecast_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3d0af809-9d2e-4fa3-85bd-f054272c815b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(restructured_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "863b22b5-5889-4990-a37c-9c2a8d888e32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# restructure_forecast(get_forecast('London'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7075725-7642-4cb2-884c-bce866644352",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_specific_forecast(forecast_data, query):\n",
    "    \"\"\"\n",
    "    Extracts specific forecast information based on user queries.\n",
    "    \n",
    "    Args:\n",
    "    forecast_data (dict): The structured forecast data.\n",
    "    query (str): The user's query.\n",
    "    \n",
    "    Returns:\n",
    "    str: The relevant forecast information.\n",
    "    \"\"\"\n",
    "    today = datetime.today()\n",
    "    query = query.lower()\n",
    "\n",
    "    if 'tomorrow' in query:\n",
    "        target_date = (today + timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "    elif 'day after tomorrow' in query:\n",
    "        target_date = (today + timedelta(days=2)).strftime('%Y-%m-%d')\n",
    "    else:\n",
    "        # Extract specific date if mentioned in the query\n",
    "        try:\n",
    "            target_date = datetime.strptime(query.split()[-1], '%Y-%m-%d').strftime('%Y-%m-%d')\n",
    "        except ValueError:\n",
    "            # Default to today's date if no specific date is mentioned\n",
    "            target_date = today.strftime('%Y-%m-%d')\n",
    "\n",
    "    if 'morning' in query:\n",
    "        target_time = '09:00:00'\n",
    "    elif 'afternoon' in query:\n",
    "        target_time = '15:00:00'\n",
    "    elif 'evening' in query:\n",
    "        target_time = '18:00:00'\n",
    "    elif 'night' in query:\n",
    "        target_time = '21:00:00'\n",
    "    else:\n",
    "        # Default to the next available time if no specific time is mentioned\n",
    "        target_time = '12:00:00'\n",
    "\n",
    "    if target_date in forecast_data:\n",
    "        if target_time in forecast_data[target_date]:\n",
    "            forecast = forecast_data[target_date][target_time]\n",
    "            return (f\"Forecast for {target_date} at {target_time}:\\n\"\n",
    "                    f\"Temperature: {forecast['temperature']}°C\\n\"\n",
    "                    f\"Feels like: {forecast['feels_like']}°C\\n\"\n",
    "                    f\"Weather: {forecast['weather']}\\n\"\n",
    "                    f\"Humidity: {forecast['humidity']}%\\n\"\n",
    "                    f\"Wind: {forecast['wind_speed']} m/s, {forecast['wind_deg']}°\\n\"\n",
    "                    f\"Visibility: {forecast['visibility']} meters\\n\"\n",
    "                    f\"Probability of precipitation: {forecast['pop']*100}%\\n\"\n",
    "                    f\"Rain: {forecast['rain']} mm\\n\"\n",
    "                    f\"Clouds: {forecast['clouds']}%\")\n",
    "        else:\n",
    "            return f\"No forecast data available for {target_date} at {target_time}.\"\n",
    "    else:\n",
    "        return f\"No forecast data available for {target_date}.\"\n",
    "\n",
    "def get_forecast_info(city, query):\n",
    "    \"\"\"Fetches and processes the weather forecast based on the user's query.\"\"\"\n",
    "    forecast_data = get_forecast(city)\n",
    "    if isinstance(forecast_data, dict):\n",
    "        return get_specific_forecast(forecast_data, query)\n",
    "    else:\n",
    "        return forecast_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4b91e229-a47e-4912-af5f-ab8a04694db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weather Tool\n",
    "weather_tool = Tool(\n",
    "    name=\"WeatherLookup\",\n",
    "    func=get_weather_info,\n",
    "    description=\"Useful to get the current weather information for a city.\"\n",
    ")\n",
    "\n",
    "# Forecast Tool\n",
    "forecast_tool = Tool(\n",
    "    name=\"ForecastLookup\",\n",
    "    func=lambda city: get_forecast_info(city, \"Please specify a query.\"),\n",
    "    description=\"Useful to get the weather forecast for the next day for a city.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "199eea08-dbc6-4960-81e2-6d458beb475b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 24 key-value pairs and 195 tensors from ../models/Phi-3-mini-4k-instruct-gguf/Phi-3-mini-4k-instruct-q4.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = phi3\n",
      "llama_model_loader: - kv   1:                               general.name str              = Phi3\n",
      "llama_model_loader: - kv   2:                        phi3.context_length u32              = 4096\n",
      "llama_model_loader: - kv   3:                      phi3.embedding_length u32              = 3072\n",
      "llama_model_loader: - kv   4:                   phi3.feed_forward_length u32              = 8192\n",
      "llama_model_loader: - kv   5:                           phi3.block_count u32              = 32\n",
      "llama_model_loader: - kv   6:                  phi3.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   7:               phi3.attention.head_count_kv u32              = 32\n",
      "llama_model_loader: - kv   8:      phi3.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv   9:                  phi3.rope.dimension_count u32              = 96\n",
      "llama_model_loader: - kv  10:                          general.file_type u32              = 15\n",
      "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  12:                         tokenizer.ggml.pre str              = default\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32064]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32064]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32064]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 32000\n",
      "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  19:            tokenizer.ggml.padding_token_id u32              = 32000\n",
      "llama_model_loader: - kv  20:               tokenizer.ggml.add_bos_token bool             = true\n",
      "llama_model_loader: - kv  21:               tokenizer.ggml.add_eos_token bool             = false\n",
      "llama_model_loader: - kv  22:                    tokenizer.chat_template str              = {{ bos_token }}{% for message in mess...\n",
      "llama_model_loader: - kv  23:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q4_K:   81 tensors\n",
      "llama_model_loader: - type q5_K:   32 tensors\n",
      "llama_model_loader: - type q6_K:   17 tensors\n",
      "llm_load_vocab: special tokens cache size = 323\n",
      "llm_load_vocab: token to piece cache size = 0.1687 MB\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = phi3\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32064\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 4096\n",
      "llm_load_print_meta: n_embd           = 3072\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 32\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 96\n",
      "llm_load_print_meta: n_embd_head_k    = 96\n",
      "llm_load_print_meta: n_embd_head_v    = 96\n",
      "llm_load_print_meta: n_gqa            = 1\n",
      "llm_load_print_meta: n_embd_k_gqa     = 3072\n",
      "llm_load_print_meta: n_embd_v_gqa     = 3072\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 8192\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 2\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_ctx_orig_yarn  = 4096\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: model type       = 3B\n",
      "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
      "llm_load_print_meta: model params     = 3.82 B\n",
      "llm_load_print_meta: model size       = 2.23 GiB (5.01 BPW) \n",
      "llm_load_print_meta: general.name     = Phi3\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 32000 '<|endoftext|>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: PAD token        = 32000 '<|endoftext|>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_print_meta: EOT token        = 32007 '<|end|>'\n",
      "llm_load_tensors: ggml ctx size =    0.11 MiB\n",
      "llm_load_tensors:        CPU buffer size =  2281.66 MiB\n",
      "...........................................................................................\n",
      "llama_new_context_with_model: n_batch is less than GGML_KQ_MASK_PAD - increasing to 32\n",
      "llama_new_context_with_model: n_ctx      = 4096\n",
      "llama_new_context_with_model: n_batch    = 32\n",
      "llama_new_context_with_model: n_ubatch   = 32\n",
      "llama_new_context_with_model: flash_attn = 0\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:        CPU KV buffer size =  1536.00 MiB\n",
      "llama_new_context_with_model: KV self size  = 1536.00 MiB, K (f16):  768.00 MiB, V (f16):  768.00 MiB\n",
      "llama_new_context_with_model:        CPU  output buffer size =     0.12 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =    18.75 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1286\n",
      "llama_new_context_with_model: graph splits = 1\n",
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 1 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
      "Model metadata: {'tokenizer.chat_template': \"{{ bos_token }}{% for message in messages %}{% if (message['role'] == 'user') %}{{'<|user|>' + '\\n' + message['content'] + '<|end|>' + '\\n' + '<|assistant|>' + '\\n'}}{% elif (message['role'] == 'assistant') %}{{message['content'] + '<|end|>' + '\\n'}}{% endif %}{% endfor %}\", 'tokenizer.ggml.add_eos_token': 'false', 'tokenizer.ggml.add_bos_token': 'true', 'tokenizer.ggml.padding_token_id': '32000', 'tokenizer.ggml.eos_token_id': '32000', 'tokenizer.ggml.bos_token_id': '1', 'general.architecture': 'phi3', 'phi3.context_length': '4096', 'phi3.attention.head_count_kv': '32', 'general.name': 'Phi3', 'tokenizer.ggml.pre': 'default', 'phi3.embedding_length': '3072', 'tokenizer.ggml.unknown_token_id': '0', 'phi3.feed_forward_length': '8192', 'phi3.attention.layer_norm_rms_epsilon': '0.000010', 'phi3.block_count': '32', 'phi3.attention.head_count': '32', 'phi3.rope.dimension_count': '96', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '15'}\n",
      "Available chat formats from metadata: chat_template.default\n",
      "Using gguf chat template: {{ bos_token }}{% for message in messages %}{% if (message['role'] == 'user') %}{{'<|user|>' + '\n",
      "' + message['content'] + '<|end|>' + '\n",
      "' + '<|assistant|>' + '\n",
      "'}}{% elif (message['role'] == 'assistant') %}{{message['content'] + '<|end|>' + '\n",
      "'}}{% endif %}{% endfor %}\n",
      "Using chat eos_token: <|endoftext|>\n",
      "Using chat bos_token: <s>\n",
      "/home/vatsal-patel/anaconda3/envs/unsloth_env/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.3.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load Llama.cpp Model\n",
    "llm = LlamaCpp(model_path=\"../models/Phi-3-mini-4k-instruct-gguf/Phi-3-mini-4k-instruct-q4.gguf\",n_ctx=4096,n_gpu_layers=-1)  \n",
    "\n",
    "# Tools (Include both Weather and Forecast Tools)\n",
    "tools = [weather_tool, forecast_tool]\n",
    "\n",
    "# Initialize Agent\n",
    "agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99392f6-368e-4331-9167-c69612769999",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(agent.run(\"What's the forecast for tomorrow in Kalyani?\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1b9381e6-c997-4b80-b229-75e247bb834f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vatsal-patel/anaconda3/envs/unsloth_env/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     658.90 ms\n",
      "llama_print_timings:      sample time =       7.15 ms /    40 runs   (    0.18 ms per token,  5597.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9712.63 ms /   202 tokens (   48.08 ms per token,    20.80 tokens per second)\n",
      "llama_print_timings:        eval time =    2442.44 ms /    39 runs   (   62.63 ms per token,    15.97 tokens per second)\n",
      "llama_print_timings:       total time =   12191.10 ms /   241 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m To get the current weather information for Kalyani, I should use the WeatherLookup tool.\n",
      "Action: WeatherLookup\n",
      "Action Input: Kalyani\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m{\n",
      "  \"coordinates\": {\n",
      "    \"lon\": 88.4833,\n",
      "    \"lat\": 22.9833\n",
      "  },\n",
      "  \"weather\": {\n",
      "    \"id\": 501,\n",
      "    \"main\": \"Rain\",\n",
      "    \"description\": \"moderate rain\",\n",
      "    \"icon\": \"10d\"\n",
      "  },\n",
      "  \"temperature\": {\n",
      "    \"current\": 26.95,\n",
      "    \"feels_like\": 29.27,\n",
      "    \"min\": 26.95,\n",
      "    \"max\": 26.95\n",
      "  },\n",
      "  \"pressure\": {\n",
      "    \"sea_level\": 997,\n",
      "    \"ground_level\": 996\n",
      "  },\n",
      "  \"humidity\": 76,\n",
      "  \"visibility\": 7886,\n",
      "  \"wind\": {\n",
      "    \"speed\": 4.1,\n",
      "    \"deg\": 215,\n",
      "    \"gust\": 7.69\n",
      "  },\n",
      "  \"clouds\": {\n",
      "    \"all\": 100\n",
      "  },\n",
      "  \"rain\": {\n",
      "    \"1h\": 1.32\n",
      "  },\n",
      "  \"dt\": 1719920313,\n",
      "  \"sys\": {\n",
      "    \"type\": 1,\n",
      "    \"id\": 9114,\n",
      "    \"country\": \"IN\",\n",
      "    \"sunrise\": 1719876266,\n",
      "    \"sunset\": 1719924930\n",
      "  },\n",
      "  \"timezone\": 19800,\n",
      "  \"id\": 1268293,\n",
      "  \"name\": \"Kalyani\",\n",
      "  \"cod\": 200\n",
      "}\u001b[0m\n",
      "Thought:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     658.90 ms\n",
      "llama_print_timings:      sample time =      11.21 ms /    63 runs   (    0.18 ms per token,  5619.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =   17674.99 ms /   424 tokens (   41.69 ms per token,    23.99 tokens per second)\n",
      "llama_print_timings:        eval time =    4561.88 ms /    63 runs   (   72.41 ms per token,    13.81 tokens per second)\n",
      "llama_print_timings:       total time =   22298.45 ms /   487 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m The current weather in Kalyani is showing moderate rain with a temperature of approximately 27 degrees Celsius.\n",
      "Final Answer: The current weather in Kalyani is rainy with temperatures around 27 degrees Celsius and wind speeds at about 4 km/h.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The current weather in Kalyani is rainy with temperatures around 27 degrees Celsius and wind speeds at about 4 km/h.\n"
     ]
    }
   ],
   "source": [
    "# Example Usage\n",
    "print(agent.run(\"Can you tell me current weather in Kalyani?\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "935b7e08-4b7b-4c8d-be43-1df13d2fc408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     658.90 ms\n",
      "llama_print_timings:      sample time =      11.83 ms /    31 runs   (    0.38 ms per token,  2620.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1381.28 ms /    18 tokens (   76.74 ms per token,    13.03 tokens per second)\n",
      "llama_print_timings:        eval time =    2321.23 ms /    30 runs   (   77.37 ms per token,    12.92 tokens per second)\n",
      "llama_print_timings:       total time =    3742.63 ms /    48 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m I need to use a tool that provides weather forecasts.\n",
      "Action: ForecastLookup\n",
      "Action Input: Kalyani\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mNo forecast data available for 2024-07-02.\u001b[0m\n",
      "Thought:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     658.90 ms\n",
      "llama_print_timings:      sample time =      18.53 ms /    48 runs   (    0.39 ms per token,  2590.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1230.21 ms /    23 tokens (   53.49 ms per token,    18.70 tokens per second)\n",
      "llama_print_timings:        eval time =    3509.81 ms /    47 runs   (   74.68 ms per token,    13.39 tokens per second)\n",
      "llama_print_timings:       total time =    4804.46 ms /    70 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m The provided date is in the future; I should request tomorrow's forecast instead.\n",
      "Action: ForecastLookup\n",
      "Action Input: Kalyani (with today's date plus one day)\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mError: Could not fetch forecast data.\u001b[0m\n",
      "Thought:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     658.90 ms\n",
      "llama_print_timings:      sample time =      27.69 ms /    87 runs   (    0.32 ms per token,  3142.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     746.65 ms /    14 tokens (   53.33 ms per token,    18.75 tokens per second)\n",
      "llama_print_timings:        eval time =    6171.27 ms /    86 runs   (   71.76 ms per token,    13.94 tokens per second)\n",
      "llama_print_timings:       total time =    7014.63 ms /   100 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m There seems to be an issue with accessing forecast data; I might need a different approach or verify if the city name is correct and the current date falls within acceptable ranges for the API.\n",
      "\n",
      "\n",
      "Since both tools failed, let's retry without specifying future dates, as it may not work properly.\n",
      "\n",
      "Action: ForecastLookup\n",
      "Action Input: Kalyani (current date)\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mError: Could not fetch forecast data.\u001b[0m\n",
      "Thought:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     658.90 ms\n",
      "llama_print_timings:      sample time =      28.65 ms /    90 runs   (    0.32 ms per token,  3141.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     978.76 ms /    14 tokens (   69.91 ms per token,    14.30 tokens per second)\n",
      "llama_print_timings:        eval time =    6589.16 ms /    89 runs   (   74.04 ms per token,    13.51 tokens per second)\n",
      "llama_print_timings:       total time =    7670.31 ms /   103 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m The API issues persist; I should check the validity of the city name and ensure today's date is within a reasonable range for the tool to access weather information.\n",
      "\n",
      "After verifying the city name and assuming an issue with the system, we proceed with checking current weather conditions as they might inform us about tomorrow's forecast:\n",
      "\n",
      "Action: WeatherLookup\n",
      "Action Input: Kalyani\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m{\n",
      "  \"coordinates\": {\n",
      "    \"lon\": 88.4833,\n",
      "    \"lat\": 22.9833\n",
      "  },\n",
      "  \"weather\": {\n",
      "    \"id\": 501,\n",
      "    \"main\": \"Rain\",\n",
      "    \"description\": \"moderate rain\",\n",
      "    \"icon\": \"10d\"\n",
      "  },\n",
      "  \"temperature\": {\n",
      "    \"current\": 26.95,\n",
      "    \"feels_like\": 29.27,\n",
      "    \"min\": 26.95,\n",
      "    \"max\": 26.95\n",
      "  },\n",
      "  \"pressure\": {\n",
      "    \"sea_level\": 997,\n",
      "    \"ground_level\": 996\n",
      "  },\n",
      "  \"humidity\": 76,\n",
      "  \"visibility\": 7886,\n",
      "  \"wind\": {\n",
      "    \"speed\": 4.1,\n",
      "    \"deg\": 215,\n",
      "    \"gust\": 7.69\n",
      "  },\n",
      "  \"clouds\": {\n",
      "    \"all\": 100\n",
      "  },\n",
      "  \"rain\": {\n",
      "    \"1h\": 1.32\n",
      "  },\n",
      "  \"dt\": 1719920313,\n",
      "  \"sys\": {\n",
      "    \"type\": 1,\n",
      "    \"id\": 9114,\n",
      "    \"country\": \"IN\",\n",
      "    \"sunrise\": 1719876266,\n",
      "    \"sunset\": 1719924930\n",
      "  },\n",
      "  \"timezone\": 19800,\n",
      "  \"id\": 1268293,\n",
      "  \"name\": \"Kalyani\",\n",
      "  \"cod\": 200\n",
      "}\u001b[0m\n",
      "Thought:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     658.90 ms\n",
      "llama_print_timings:      sample time =      15.70 ms /    81 runs   (    0.19 ms per token,  5159.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15957.71 ms /   424 tokens (   37.64 ms per token,    26.57 tokens per second)\n",
      "llama_print_timings:        eval time =    6081.97 ms /    81 runs   (   75.09 ms per token,    13.32 tokens per second)\n",
      "llama_print_timings:       total time =   22112.31 ms /   505 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m I have current weather information. This may help infer tomorrow's forecast if there are patterns or similar conditions expected to continue.\n",
      "Final Answer: Kalyani is currently experiencing moderate rain with no specific data for the next day, but consistent rainy weather suggests that it might continue into tomorrow as well. However, this inference should be taken cautiously without official data.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Kalyani is currently experiencing moderate rain with no specific data for the next day, but consistent rainy weather suggests that it might continue into tomorrow as well. However, this inference should be taken cautiously without official data.\n"
     ]
    }
   ],
   "source": [
    "print(agent.run(\"What's the forecast for tomorrow in Kalyani?\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b6306d-238b-4900-9642-5dbcd258c293",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Unsloth)",
   "language": "python",
   "name": "unsloth_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
